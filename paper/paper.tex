%\documentclass[manuscript]{aastex} %one-column, double-spaced document
\documentclass[preprint]{aastex} %double-column, single-spaced document:
%\documentclass[iop,floatfix]{emulateapj} 

\usepackage{hyperref}
%\usepackage{graphicx}
%\usepackage{apjfonts}
\usepackage{enumerate}
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\usepackage{bm}

\newcommand{\prob}{{\rm prob}}
\newcommand{\qN}{\{q_i\}_{i=1}^N}
\newcommand{\yN}{\{y_i\}_{i=1}^N}
\newcommand{\vt}{\vec{\theta}}
\newcommand{\vstar}{\vt_{\star}}
\newcommand{\vN}{\vt_{\rm N}}
\newcommand{\vc}{\vec{c}}
\newcommand{\fM}{f_{\rm M}}
\newcommand{\fD}{f_{\rm D}}
\newcommand{\vD}{\vec{D}}
\newcommand{\dd}{\,{\rm d}}
\newcommand{\trans}{\mathsf{T}}

%\slugcomment{}
%\shorttitle{}
%\shortauthors{}

\begin{document}

\title{A Bayesian method for inference of fundamental stellar parameters}
\author{\today{}\\
\medskip
Ian~Czekala\altaffilmark{1} and Sean M. Andrews\altaffilmark{1}
%Author2\altaffilmark{2},
}

\altaffiltext{1}{Harvard-Smithsonian Center for Astrophysics, 60 Garden Street MS 10, Cambridge, MA 02138}
%\altaffiltext{2}{Institution 2}
\email{iczekala@cfa.harvard.edu}

%\begin{abstract}
%\end{abstract}
%\keywords{}

%\begin{figure}[htb]
%\begin{center}
%\includegraphics{file}
%\caption{}
%\label{fig:}
%\end{center}
%\end{figure}

\section{The model}

To summarize our model, we use Bayes rule to design a posterior probability function
\begin{equation}
  \overbrace{p(\vt | \vD)}^{\rm posterior} \propto \underbrace{p(\vD | \vt)}_{\rm likelihood} \; \overbrace{p(\vt)}^{\rm prior}
  \label{eqn:posterior}
\end{equation}
where the parameter vector is comprised of both stellar parameters and calibration parameters $\vt = \{\vstar, \vN \}$. Stellar parameters include $\vstar = \{T_{\rm eff}, \log(g), v \sin i, v_z, A_v \}$ while the data vector $\vD = \fD(\lambda)$ represents the a high resolution spectrum. In our immediate case of our companion paper, this is a 51-order echelle spectrum from TRES at a resolution of $R=48,000$ ($6.8\;{\rm km/s}$) and spanning the full optical range.

Although per-pixel photon counting errors are Poisson, we can safely assume that we have enough counts that we are in the Gaussian limit. Then our likelihood function becomes a pixel-by-pixel $\chi^2$ comparison between the data spectrum $\fD$, and the model spectrum $\fM$, summed over the wavelength axis.\footnote{We must necessarily mask certain wavelength regions of the T Tauri spectra that are contaminated (one might also say ``made more interesting'') by the astrophysical realities of accretion or stellar spots (such as the Balmer lines, which are in emission).  We also accept the assumption that rotation or accretion onto the star does not fundamentally alter the structure of the model atmosphere that generates the model spectrum and that a spectral comparison of the ``clean'' regions of the spectrum is valid.} 
\begin{equation}
 p(\vD | \vt) = {\cal L} \propto \exp \left(-\frac{\chi^2}{2} \right)
\end{equation}

\begin{equation}
  \chi^2 = \sum_\lambda \left [\frac{\fM(\lambda | \vstar) - k(\lambda | \vN) \fD(\lambda) }{\sigma(\lambda)} \right ]^2
\end{equation}
In the future, we could modify our likelihood function to use a Student-t statistic instead of a Gaussian, such that it would be more robust in the presence of outlier pixels, however this does not seem necessary at the moment. To start, we will assume flat priors on $\vstar$ and $\vN$ and then relax this assumption later. Then the logarithm of our posterior probability function is then
\begin{equation}
  \ln \bigl [p(\vt | \vD) \bigr] \propto - \frac{1}{2} \sum_\lambda \left [\frac{\fM(\lambda | \vstar) - k(\lambda | \vN) \fD(\lambda) }{\sigma(\lambda)} \right ]^2
  \label{eqn:lnprob}
\end{equation}
To generate a model spectrum given a set of parameters $\fM(\vt)$, a model spectrum is created by linearly interpolating between grid points of a high-resolution PHOENIX model stellar spectra ($R = 500,000$), rotationally broadened, instrumentally broadened, Doppler shifted, extinction corrected, and downsampled to the exact pixels of the TRES spectrum. $\sigma(\lambda)$ is the RMS scatter of the continuum (measured in a line-free region) inversely scaled by the blaze function in each order, to account for Poisson photon counting errors. For some data reduction pipelines, a per-pixel ``sigma spectrum'' that accounts for spectral extraction errors due to night sky line contamination or low signal to noise is available, and should be used instead. The data prefactor $k(\lambda | \vN)$ is a systematic error term that aims to account for errors in the blaze-correction or flux-calibration. In our case, $\vN = \{c_0, c_1, \ldots, c_N\}$ are a set of 4 Chebyshev polynomial coefficients for each order. This amounts to a ``re-fluxing'' following the techniques of \citet{elh+06}. Additionally, we can add priors to limit the degree of re-fluxing (for example 20\%) to be consistent with a systematic noise floor for flux-calibration determined independently through calibration tests on TRES using standard stars.

\subsection{Nuisance parameters}
In order to understand the effects of the $k(\lambda | \vN)$ term, we now consider its effects on just one order. The first four Chebyshev polynomials are 
\begin{align*}
  T_0(x) &= 1\\
  T_1(x) &= x\\
  T_2(x) &= 2 x^2 - 1\\
  T_3(x) &= 4 x^3 - 3x\\
\end{align*}
In our implementation, we map the full range of a specific order $\lambda \in [\lambda_{\rm min}, \lambda_{\rm max}]$ to $x \in [-1, 1]$ (or we can map pixel number). Then, for a given set of Chebyshev coefficients, $\vN = \vc = \{ c_0, c_1, c_2, \ldots, c_N \}$, we have 

\begin{align}
  k(\lambda | \vN) &= c_0 T_0(\lambda) + c_1 T_1(\lambda) + \ldots + c_N T_N(\lambda) \\
  k(\lambda | \vN) &= \sum^N_{i = 0} c_i T_i(\lambda)
\end{align}

using this, we can rewrite Equation~\ref{eqn:lnprob} as 
\begin{equation}
  \ln \bigl [p(\vt | \vD) \bigr] \propto - \frac{1}{2} \sum_\lambda \left [\frac{\fM(\lambda | \vstar) - \bigl [ \sum^N_{i = 0} c_i T_i(\lambda) \bigr ] \fD(\lambda) }{\sigma(\lambda)} \right ]^2
  \label{eqn:lnprob2}
\end{equation}
To simplify the following discussion, we consider just one wavelength $\lambda_i$ and then generalize this to a sum over $\lambda$ later. If we expand out the square in Equation~\ref{eqn:lnprob2}, then for a given $\lambda_i$ we have
\begin{equation}
 \ln \bigl [p(\vt | \lambda_i) \bigr] \propto -\frac{1}{2 \sigma^2} \bigl [ \fM^2 - 2 \fM \fD \sum_n c_n T_n + \fD^2 \sum_n \sum_m c_n T_n c_m T_m \bigr ]
 \label{eqn:lnprob_lambda}
 \end{equation}
 where $\sigma$, $\fM$, $\fD$, and $T_{n,m}$ are all evaluated at $\lambda_i$

To simplify this math, we can rewrite the Chebyshev coefficients and polynomials as column vectors $\vc$ and $\vec{T}(\lambda)$, respectively
\begin{equation}
  \vc = 
  \begin{bmatrix}
    c_0\\
    c_1\\
    \vdots\\
    c_N
  \end{bmatrix}
  \hspace{3cm}
\vec{T}(\lambda) = 
\begin{bmatrix}
T_0(\lambda)\\
T_1(\lambda)\\
\vdots\\
T_N(\lambda)\\
\end{bmatrix}
\end{equation}

then 
\begin{equation}
  k(\lambda | \vN) = \sum^N_{i = 0} c_i T_i = \vec{T}^\trans \cdot \vc
\end{equation}
If we let 
\begin{equation}
  {\bm W}(\lambda) = \vec{T} \cdot \vec{T}^\trans = 
  \begin{bmatrix}
T_0 T_0 & T_0 T_1 &  \hdots & T_0 T_N \\
T_1 T_0 & T_1 T_1 &  \hdots & T_1 T_N \\
\vdots  & \vdots  &  \ddots & \vdots \\
T_N T_0 & T_N T_1 &  \hdots & T_N T_N \\
  \end{bmatrix}
\end{equation}
then we have
\begin{equation}
  \sum_n \sum_m c_n T_n c_m T_m = \vc^\trans \cdot {\bm W} \cdot \vc
\end{equation}
and we can rewrite Equation~\ref{eqn:lnprob_lambda} as 
\begin{equation}
  \ln \bigl [p(\vt | \lambda_i) \bigr] \propto -\frac{1}{2 \sigma^2} \bigl [ \fM^2 - 2 \fM \fD\, \vec{T}^\trans \vc \; + \fD^2 \, \vc^\trans {\bm W}  \vc \bigr ]
\end{equation}

Because matrix multiplication is associative, we can sum ${\bm W(\lambda)}$ and $\vec{T}^\trans(\lambda)$ across all $\lambda$, and define
\begin{align}
  {\bm A} &= \sum_\lambda \frac{\fD(\lambda)}{\sigma^2(\lambda)} {\bm W}(\lambda)\\
  \vec{B}^\trans(\vstar) &= \sum_\lambda \frac{\fM(\lambda | \vstar) \fD(\lambda)}{\sigma^2(\lambda)} \vec{T}^\trans(\lambda)\\
  g(\vstar) &= -\frac{1}{2} \sum_\lambda \frac{\fM^2(\lambda|\vstar)}{\sigma^2(\lambda)}\\
\end{align}
Now we can rewrite Equation~\ref{eqn:lnprob2} as 
\begin{equation}
  \ln \bigl (p(\vstar, \vN | \vD) \bigr) \propto - \frac{1}{2} \vc^\trans {\bm A} \vc + \vec{B}^\trans(\vstar) \vc + g(\vstar)
  \label{eqn:lnprob_matrix}
\end{equation}
where remember $\vN = \{c_0, c_1, \ldots, c_N \}$. Now we have
\begin{equation}
  p(\vt | \vD) = p(\vstar, \vN | \vD) \propto \exp \left ( - \frac{1}{2} \vc^\trans {\bm A} \vc + \vec{B}^\trans(\vstar) \vc + g(\vstar) \right )
  \label{eqn:posterior_vec}
\end{equation}
Because this is a multi-dimensional Gaussian in the Chebyshev coefficients and the parameters we are most interested in are $\vstar$, we can analytically marginalize out the nuisance parameters
\begin{equation}
  p(\vstar | \vD) = \int p(\vstar, \vN | \vD) \dd \vN
\end{equation}
The analytic multi-dimensional Gaussian integral with linear term \citep{sgd+09} yields 
\begin{align}
  p(\vstar | \vD) &= \int \exp \left ( - \frac{1}{2} \vc^\trans {\bm A} \vc + \vec{B}^\trans(\vstar) \vc + g(\vstar) \right ) \dd \vc\\
  p(\vstar | \vD) &= \sqrt{\frac{(2 \pi )^N}{ {\rm det} \bigl |{\bm A} \bigr |}} \exp{ \left ( \frac{1}{2} \vec{B}^\trans {\bm A}^{-1} \vec{B} + g \right )}
\end{align}
This result means that for any given set of parameters $\vstar$, we only need to calculate $\vec{B}(\vstar)$ and $g(\vstar)$; ${\bm A}(\vD)$ can be computed once and stored for the remainder of the MCMC run.

\subsection{Including Gaussian priors on nuisance parameters}
In order to constrain the degree of ``re-fluxing'' to be consistent with an independent determination of the systematic error floor in flux-calibration (for example, 20\%), we can add Gaussian priors that limit the coefficient of each Chebyshev polynomial to within a percentage of no correction. For example, we might wish to limit the multiplicative linear term $c_1$ to within an amplitude of $\pm 0.2$.

This corresponds to a prior on the nuisance parameters of
\begin{equation}
  p(\vN) \propto \exp \left ( -\frac{1}{2} (\vc - \vec{\mu})^\trans {\bm D} (\vc - \vec{\mu}) \right )
  \label{eqn:nuisance_prior} 
\end{equation}
where 
\begin{equation}
  {\bm D} = 
  \begin{bmatrix}
    \sigma_0^{-2} & 0 & \hdots & 0 \\
    0 & \sigma_1^{-2} & \hdots & 0 \\
    \vdots & \vdots & \ddots & 0 \\
    0 & 0 & \hdots & \sigma_N^{-2} \\
  \end{bmatrix}
\end{equation}
$\sigma_i$ represents the width of the Gaussian prior on the i-th Chebyshev coefficient. We can rewrite Equation~\ref{eqn:posterior} with priors as
\begin{align}
  p(\vstar, \vN | \vD) &\propto p( \vD | \vstar, \vN) p(\vN) p(\vstar)\\
  p(\vstar, \vN | \vD) &\propto \exp \left ( - \frac{1}{2} \vc^\trans {\bm A} \vc + \vec{B}^\trans(\vstar) \vc + g(\vstar) \right )  \exp \left ( -\frac{1}{2} (\vc - \vec{\mu})^\trans {\bm D} (\vc - \vec{\mu}) \right ) p(\vstar)
  \label{eqn:posterior_prior}
\end{align}
we can expand and rearrange the argument of Equation~\ref{eqn:nuisance_prior} to a similar form 
\begin{align}
  -\frac{1}{2} (\vc - \vec{\mu})^\trans {\bm D} (\vc - \vec{\mu}) &= \frac{1}{2}\left ( -\vc^\trans {\bm D} \vc + \vc^\trans {\bm D} \vec{\mu} + \vec{\mu}^\trans {\bm D} \vc - \vec{\mu}^\trans {\bm D} \vec{\mu} \right )\\
  &= -\frac{1}{2} \vc^\trans {\bm D} \vc + ({\bm D} \vec{\mu})^\trans \vc - \frac{1}{2} \vec{\mu}^\trans {\bm D} \vec{\mu}
\end{align}
then we can rewrite
\begin{align}
  {\bm A}^\prime({\bm D}) &= \sum_\lambda \frac{\fD(\lambda)}{\sigma^2(\lambda)} {\bm W}(\lambda) + {\bm D}\\
  \vec{B}^{\prime\trans}(\vstar | \vec{\mu}, {\bm D}) &= \sum_\lambda \frac{\fM(\lambda | \vstar) \fD(\lambda)}{\sigma^2(\lambda)} \vec{T}^\trans(\lambda) + ({\bm D} \vec{\mu})^\trans \\
  g^\prime(\vstar | \vec{\mu}, {\bm D}) &= -\frac{1}{2} \sum_\lambda \frac{\fM^2(\lambda|\vstar)}{\sigma^2(\lambda)}- \frac{1}{2} \vec{\mu}^\trans {\bm D} \vec{\mu}\\
\end{align}
The result is the posterior probability function for our stellar parameters $\vt$ that has already been marginalized over the nuisance parameters with Gaussian priors.
\begin{equation}
  \boxed{
  p(\vstar | \vD) = \sqrt{\frac{(2 \pi )^N}{ {\rm det} \bigl |{\bm A}^\prime \bigr |}} \exp{ \left ( \frac{1}{2} \vec{B}^{\prime\trans} {\bm A}^{\prime -1} \vec{B}^\prime + g^\prime \right )} p(\vstar)
}
\end{equation}


\acknowledgments
IC would like to graciously acknowledge Gregory Green, Doug Finkbeiner, and Daniel Eisenstein for many fruitful discussions about statistics and spectroscopy. 

%\appendix
%
%\section{}
%
%\begin{deluxetable}{ll}
%\tablecaption{\label{table:} Title}
%\tablehead{\colhead{Col1} & \colhead{Col2}}
%\startdata
%\enddata
%\tablecomments{}
%\end{deluxetable}

\bibliography{disks}
\bibliographystyle{hapj}
\end{document}


